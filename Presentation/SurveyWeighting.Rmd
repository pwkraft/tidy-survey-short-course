---
title: "Tidy Survey Analysis in R using the srvyr Package"
subtitle: "Master in Computational Social Science"
author:
   - Patrick Kraft, IC3JM / UC3M
date: "November 26, 2024"
output:
  xaringan::moon_reader:
    css: xaringan-themer-mod.css
    nature:
      slideNumberFormat: "%current%"
      highlightStyle: github
      highlightLines: true
      ratio: 16:9
      countIncrementalSlides: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, tidy = FALSE)
```

class: inverse center middle

# Introduction

```{css sizesetup, echo = FALSE}
.small .remark-code { /*Change made here*/
font-size: 80% !important;
}
.smaller .remark-code { /*Change made here*/
font-size: 70% !important;
}
```


---
## Overview

- At the end of this workshop series, you will be able to 
   - Specify a survey design in R to create a survey object
   - Calculate point estimates and their standard errors with survey data 
      - Means, quantiles, and ratios
      - Proportions, totals, and counts
   - Perform t-tests
   - Fit regression models

- Main resources:
   - Stephanie A. Zimmer, Rebecca J. Powell, and Isabella C. Velásquez. 2024. [Exploring Complex Survey Data Analysis Using R](https://tidy-survey-r.github.io/tidy-survey-book/). CRC Press
   - Online documentation for the [sampling package](https://cran.r-project.org/web/packages/sampling/index.html)
   
### Acknowledgments

This workshop is based on material for the course "Tidy Survey Analysis in R" taught by Stephanie Zimmer, Rebecca Powell, and Isabella Velásquez at the conference of the American Association for Public Opinion Research (AAPOR).

???

## Workshop Roadmap

- Survey design objects, constructing replicate weights, and creating derived variables
- Analysis of continuous data (with time for practice)
- Analysis of categorical data (with time for practice)

## What we won't cover

- We will not be going over the following but provide some resources at the end
   - Calibration, post-stratification, raking, etc.
   - Survival analysis
   - Multilevel models



---
class: inverse center middle

# Specifying sample design objects


---
## Review of sampling designs

- **Simple random sampling:** every unit has the same chance of being selected
   - Without replacement: units can only be selected once
   - With replacement: units can be selected more than once

- **Systematic sampling:** sample $n$ individuals from a ordered list and sampling individuals at an interval with a random starting point

- **Probability proportional to size:** probability of selection is proportional to "size"

- **Stratified sampling:** divide population into mutually exclusive subgroups (strata). Randomly sample within each stratum

- **Clustered sampling:** divide population into mutually exclusive subgroups (clusters). Randomly sample clusters and then individuals within clusters

???

- If $N$ is big enough then treat as with replacement. If $N$ is not too big and WOR, need FPC
- PPS - size is possibly related to outcome. Several methods (not discussed today)
- Stratified clustered design are very common in population surveys


---
## Create Your Own Probability Sample

The `sampling` package provides a set of useful functions for...

- **Sampling:** Stratification, two-stage, unequal probabilities, balanced sampling

- **Estimation:** calibration and regression estimator

- **Tools:** computation of inclusion probabilities, crossing strata

- **Data bases:** Swiss municipalities, Belgian municipalities.

### Install and load the package

```{r}
install.packages(setdiff("sampling", rownames(installed.packages())))
library(sampling)
```


---
## Example: Simple random sampling w/o replacement

Select a sample of size 10 out of a population of 50:
```{r}
s <- srswor(
   n = 10,  ## Sample size
   N = 50   ## Population size
)

matrix(s, nrow = 5, byrow = TRUE)
```

Here are the selected sample IDs:
```{r}
which(s==1)
```


---
## Example: Stratified sampling

.pull-left[
Variable of stratification (3 strata):
```{r}
group <- rep(1:3, each = 5)
```

Matrix of balancing variables:
```{r}
X <- cbind(1:15)
```

Vector of inclusion probabilities (sample size of 9):
```{r}
pik <- rep(3/5, times = 15)
```

Selection of a stratified sample
```{r}
s <- balancedstratification(
   X = X, strata = group, pik = pik, 
   comment = FALSE
)
```
]
.pull-right[
The sample is:
```{r}
matrix(s, nrow = 3, byrow = TRUE)
which(s==1)
```
]

---
## Example: Clustered sampling

Selection of 2 clusters:
```{r}
s <- balancedcluster(
   X = X, m = 2, cluster = group,
   selection = 2, # cluster selection equal or by size
   comment = FALSE
)
```

.pull-left[
The sample of clusters with the inclusion probabilities of the clusters:
```{r}
head(s)
```
]
.pull-right[
The selected clusters:
```{r}
unique(group[s[,1]==1])
```

The selected units:
```{r} 
which(s[,1]==1)
```
]

   
---
## Overview of Survey Analysis using `srvyr` Package

1. Create a `tbl_svy` object using: `as_survey_design` or `as_survey_rep`

2. Subset data (if needed) using `filter` (subpopulations)

3. Specify domains of analysis using `group_by` 

4. Within `summarize`, specify variables to calculate including means, totals, proportions, quantiles and more

???

`as_survey_rep`: for replicate weights


---
## Set-up for Analysis

- `srvyr` package uses tidy-syntax but uses the `survey` package behind it to do calculations

- Install both packages (and a few others):

```{r inst_srv2, message=FALSE, warning=FALSE}
# Install survey and srvyr packages (only once!)
install.packages(setdiff(c("survey", "srvyr", "tidyverse", "here"), 
                         rownames(installed.packages())))

# Load packages
library(tidyverse) # for tidyverse
library(here) # for file paths
library(survey) # for survey analysis
library(srvyr) # for tidy survey analysis
```

???

- need to install github version of survey package if you want CIs with quantiles: 
remotes::install_github("bschneidr/r-forge-survey-mirror")

---
## Determining the design

- Look at documentation associated with the analysis file

- Keywords to look for: methodology, design, analysis guide, technical documentation

- Documentation will indicate the variables needed to specify the design. Look for:
   - weight (almost always)
   - strata and/or clusters/PSUs. Sometimes pseudo-strata and pseudo-cluster OR
   - replicate weights (this is used instead of strata/clusters for analysis)
   - might also see finite population correction or population sizes

- Documentation may include syntax for SAS, SUDAAN, Stata and/or R!

???

PSU: primary sampling unit
pseudo: for anonymity


---
class: inverse center middle

# Survey Datasets


---
## American National Election Study (ANES) 2020

- Pre and post election surveys

- Fielded almost every 2 years since 1948

- Topics include voter registration status, candidate preference, opinions on country and government, party and ideology affiliation, opinions on policy, news sources, and more

- Collaboration of Stanford, University of Michigan - funding by the National Science Foundation

- <b>Target Population</b>: US citizens, 18 and older living in US 

- <b>Mode</b>: Web, videoconference, or telephone.

- <b>Sample Information</b>: Pseudo-strata and pseudo-cluster included for variance estimation

???

- We have subset the columns of this data and created derived variables, code in repository
- Historically FTF existed but pandemic prevented this


---
## American National Election Study (ANES) 2020

- https://electionstudies.org/data-center/2020-time-series-study/

- Opened the file "User Guide and Codebook"

- Section "Data Analysis, Weights, and Variance Estimation": Page 8-12 includes information on weights and strata/cluster variables

> For analysis of the complete set of cases using pre-election data only, including all
> cases and representative of the 2020 electorate, use the full sample pre-election
> weight, V200010a. For analysis including post-election data for the complete set of
> participants (i.e., analysis of post-election data only or a combination of pre- and
> post-election data), use the full sample post-election weight, V200010b.
> Additional weights are provided for analysis of subsets of the data...

For weight | Use variance unit/PSU/cluster | and use variance stratum
-----------|-------------------------------|-------------------------
V200010a| V200010c| V200010d
V200010b| V200010c| V200010d


---
## Residential Energy Consumption Survey (RECS) 2015

- Energy consumption/expenditures collected through energy suppliers

- Fielded 14 times between 1950 and 2015

- Topics include appliances, electronics, heating, a/c, temperatures, water heating, lighting, energy bills, respondent demographics, and energy assistance

- Funded by the Energy Information Administration

- <b>Target Population</b>: Primary occupied housing units in the US

- <b>Mode</b>: In-person, paper, and web interview mode

- <b>Sample Information</b>: BRR Replicate weights included for variance estimation

https://www.eia.gov/consumption/residential/index.php

???
- We have subset the columns of this data and created derived variables, code in repository


---
## Residential Energy Consumption Survey (RECS) 2015

- https://www.eia.gov/consumption/residential/data/2015/index.php?view=microdata

- Opened the file "Using the 2015 microdata file to compute estimates and standard errors (RSEs)"

- Page 4:

> The following instructions are examples for calculating any RECS estimate using the final weights
> (NWEIGHT) and the associated RSE using the replicate weights (BRRWT1 – BRRWT96).

> Let $\epsilon$ be the Fay coefficent ... and $\epsilon=0.5$

- Page 9: Syntax given for survey package which is similar to srvyr (as we will see)

```{r recsexamp, eval=FALSE}
library(survey)
RECS15 <- read.csv(file='< location where file is stored >', header=TRUE, sep=",")
sampweights <- RECS15$NWEIGHT
brrwts <- RECS15[, grepl(“^BRRWT”, names(RECS15))]
des <- svrepdesign(weights=sampweights, repweights=brrwts, type="Fay",
                   rho=0.5, mse=TRUE, data=RECS15)
```

???

The Fay–Herriot model is a statistical model which includes some distinct variation for each of several subgroups of observations. It is an area-level model, meaning some input data are associated with sub-aggregates such as regions, jurisdictions, or industries. The model produces estimates about the subgroups. The model is applied in the context of small area estimation in which there is a lot of data overall, but not much for each subgroup.


---
## Specify the sampling design

- This creates a `tbl_svy` object that then correctly calculates weighted estimates and SEs.

```{r sd_tsl_syn, eval=FALSE}
as_survey_design(
   .data,
   ids = NULL,#cluster IDs/PSUs
   strata = NULL,#strata variables
   variables = NULL,#defaults to all in .data
   fpc = NULL,#variables defining the finite population correct
   nest = FALSE,#TRUE/FALSE - relabel clusters to nest within strata
   check_strata = !nest, #check that clusters are nested in strata
   weights = NULL,# weight variable
   ...
)
```


---
## Syntax for common designs

```{r sd_tsl_gen_ex, eval=FALSE}
# simple random sample (SRS)
apisrs %>% as_survey_design(fpc = fpc)

# stratified sample
apistrat %>% as_survey_design(strata = stype, weights = pw)

# one-stage cluster sample
apiclus1 %>% as_survey_design(ids = dnum, weights = pw, fpc = fpc)

# two-stage cluster sample, weights computed from pop size
apiclus2 %>% as_survey_design(ids = c(dnum, snum), fpc = c(fpc1, fpc2))

# stratified, cluster design
apistrat %>% as_survey_design(ids = dnum, strata = stype, weights =pw, nest = TRUE)

```

- examples from `srvyr` help documentation

---
## ANES Example

For weight | Use variance unit/PSU/cluster | and use variance stratum
-----------|-------------------------------|-------------------------
V200010b| V200010c| V200010d

```{r anesdatin, eval=FALSE}
options(width=130)
anes <- read_rds(here("Data", "anes_2020.rds")) %>%
   mutate(Weight=V200010b/sum(V200010b)*231592693) 
   # adjust weight to sum to citizen pop, 18+ in Nov 2020 per ANES methodology documentation

anes_des <- anes %>%
   as_survey_design(weights = Weight,
                    strata = V200010d,
                    ids = V200010c,
                    nest = TRUE)
summary(anes_des)
```

???

- provides weights that sum to the sample, but we want to get population estimates
- need to adjust the weight to get it to the population count


---
## ANES Example (cont'd)

.smaller[
```{r anesprint, ref.label="anesdatin", echo=FALSE}
```
]


---
## RECS Example

- Final weights: NWEIGHT
Replicate weights: BRRWT1 – BRRWT96

```{r recsin, error=FALSE, warning=FALSE, eval=FALSE}
options(width=130)
recs <- read_rds(here("Data", "recs.rds"))

recs_des <- recs %>%
   as_survey_rep(weights=NWEIGHT,
                 repweights=starts_with("BRRWT"),
                 type="Fay",
                 rho=0.5,
                 mse=TRUE)

summary(recs_des)
```


---
## RECS Example (cont'd)

.smaller[
```{r recsprint, ref.label="recsin", echo=FALSE}
```
]



---
class: inverse center middle

# Continuous Dependent Variables


---
## Weighted Analysis for Continuous Variables

- Common functions for continuous summaries
   - survey_mean
   - survey_total (like sum)
   - survey_median
   - survey_quantile
   - survey_ratio

- Always call within `summarize`/`summarise`


---
## `survey_mean` Syntax

```{r survey_mean_syn3, eval=FALSE}
survey_mean(
  x,
  na.rm = FALSE,
  vartype = c("se", "ci", "var", "cv"),
  level = 0.95,
  proportion = FALSE,
  deff = FALSE,
  df = NULL,
  ...
)
```

To calculate a survey mean, we use this in `summarize`/`summarise`
```{r survey_mean_syn2, eval=FALSE}
survey_design_object %>%
   summarize(
      mean_varname=survey_mean(x = continuous_varname)
      )
```

???
Only required argument is the variable


---
## `survey_mean` Example 1: On average, how much do US households spend on energy each year?

This is an example using the `recs_des` survey design object and `survey_mean` function defaults

```{r survey_mean_ex1}
recs_des %>%
   summarize(
      TD_mean=survey_mean(x = TOTALDOL)
      )
```


---
## `survey_mean` Example 2: What is the average temperature US households set their homes to on a summer day?

Run this code. What happens?

```{r survey_mean_ex2, eval=FALSE}
recs_des %>%
   summarize(
      TD_mean=survey_mean(x = SummerTempDay)
      )
```


---
## `survey_mean` Example 2: What is the average temperature US households set their homes to on a summer day?

Run this code. What happens?

```{r survey_mean_ex2_r, error=TRUE}
recs_des %>%
   summarize(
      TD_mean=survey_mean(x = SummerTempDay)
      )
```

<b>How do we fix this code?</b>

???

- missing data in temperature, need `na.rm=TRUE`


---
## `survey_mean` Example 2: Missing data solution

```{r survey_mean_ex2_sol, error=TRUE, tidy=FALSE}
recs_des %>%
   summarize(
      TD_mean = survey_mean(
        x = SummerTempDay, 
        na.rm = TRUE )#<<
      )
```


---
## `survey_median` Syntax

```{r survey_median_syn, eval=FALSE}
survey_median(
  x,
  na.rm = FALSE,
  vartype = c("se", "ci"),
  level = 0.95,
  df = NULL,
  ...
)
```

???
Only required argument is the variable


---
## `survey_median` Example: What is the median temperature US households set their homes to on a summer day?

.pull-left[
```{r survey_median_fib, eval=FALSE}
recs_des %>%
   summarize(
      TD_median=survey_median(x=_________,
                          na.rm=_________)
      )
```
]
--
.pull-right[
```{r survey_median_fib_sol}
recs_des %>%
 summarize(
   TD_median=survey_median(x=SummerTempDay,
                           na.rm=TRUE)
 )
```
]

???

- Mean temperature set is 72.4 degrees Fahrenheit with a standard error of 0.08
- Median temperature set is 72 degrees Fahrenheit with a standard error of 0.25

REMOVED SECTION ON SURVEY QUANTILES HERE


---
## `survey_ratio` Syntax

- Note this estimates: $\sum x_i/\sum y_i$ not $\sum \frac{x_i}{y_i}$

```{r survey_ratio_syn, eval=FALSE}
survey_ratio(
  numerator, #<<
  denominator, #<<
  na.rm = FALSE,
  vartype = c("se", "ci", "var", "cv"),
  level = 0.95,
  deff = FALSE,
  df = NULL,
  ...
)
```


---
## `survey_ratio` Example: What is the average dollar per BTU spent on energy?

```{r survey_ratio_ex}
recs_des %>%
   summarize(
      DolPerBTU=survey_ratio(
         numerator = TOTALDOL, #<<
         denominator = TOTALBTU, #<<
         na.rm = TRUE
         )
      )
```

???

- BTU (British Thermal Units)

The British thermal unit (Btu) is a measure of heat, which is a form of energy. It was originally defined as the amount of heat required to raise the temperature of one pound of water by one degree Fahrenheit. It is also part of the United States customary units.[1] The SI unit for energy is the joule (J); one Btu equals about 1,055 J (varying within the range of 1,054–1,060 J depending on the specific definition of BTU; see below). 


---
## Practice time

- Open ContinuousExercises.Rmd and work through Part 1

- We will take 10 minutes. Use this time for the exercises and questions.


---
## Weighted Analysis for Continuous Variables: Domain Analysis

- If we want to get estimates by another variable, we need to add a `group_by` statement before doing the analysis.

- Example: What is the average amount of dollars spent on electricity for households that use AC and those that do not use AC?

```{r domain_ex}
recs_des %>%
  group_by(ACUsed) %>% #<<
  summarize(
    ElBill=survey_mean(DOLLAREL, 
                       na.rm=TRUE)
  )
```


---
## Domain Analysis: Totals

- If we want the overall average electric bill too, use the `cascade` function instead of `summarize`

```{r domain_ex_casc}
recs_des %>%
   group_by(ACUsed) %>%
   cascade(
      ElBill=survey_mean(DOLLAREL, 
                         na.rm=TRUE)
   )

```

<b>Note: The overall average electric bill appears as NA</b>


---
## Domain Analysis: Totals

- Also can add sample and pop sizes

```{r domain_tot}
recs_des %>%
   group_by(ACUsed) %>%
   cascade(
      ElBill=survey_mean(DOLLAREL, na.rm=TRUE),
      N=survey_total(!is.na(DOLLAREL)), #<<
      n=unweighted(sum(!is.na(DOLLAREL))) #<<
   )

```

???
- survey_total gets a weighted total
- unweighted does just that, an unweighted estimate, can also get an unweighted mean or any other stat


---
## Weighted Analysis for Specific Subpopulations

- filtering (subsetting) the data should be done AFTER specifying the design to ensure accurate standard errors

- Use the `filter` function after creating the survey design object and before summarizing

Wrong way:
```{r filter_bad, eval = FALSE}
data %>%
  filter(state=="NC") %>% #<<
  as_survey_design(...) %>%
  summarize(AvgAge=mean(Age))
```

Right way:
```{r filter_good, eval=FALSE}
data %>%
  as_survey_design(...) %>%
  filter(state=="NC") %>% #<<
  summarize(AvgAge=mean(Age))
```

???
- Required to ensure correct calculation when sub-population is not in all strata or PSUs


---
## Subpopulation Example: Average electric cost of single family homes

```{r subpop1}
recs_des %>%
  filter(HousingUnitType %in% c("Single-family detached",
                                "Single-family attached")) %>%
  summarize(
    ElBill=survey_mean(DOLLAREL, 
                       na.rm=TRUE)
  )
```

???
- Filter goes AFTER the design object
- Previous syntax showed the creation of the design object, but with this example, we already created it


---
## Comparisons with t-tests: `svyttest` Syntax

- t-tests are done in the package `survey` not `srvyr` but you can use the same design object

```{r ttest_syn1, eval=FALSE}
svyttest(formula, # outcome~group for two-sample, outcome~0 for one-sample
         design,
         na.rm = FALSE
         ....)
```

???
- Uses standard R formula notation
- will go over examples of 1-sample, 2-sample, and paired t-test


---
## `svyttest` Syntax with `%>%`

```{r ttest_syn2, eval=FALSE}
recs_des %>%
   svyttest(formula=,
            design=., #<<
            na.rm=TRUE)
```

???
- To use in tidyverse need the "dot" notation as highlighted here
- Pipe then puts the design object in the correct placement


---
## `svyttest` Syntax with `%>%`

```{r ttest_syn3, eval=FALSE}
recs_des %>%
   svyttest(design=., #<<
            formula=,
            na.rm=TRUE)
```

???
- Order doesn't matter for the arguments when you use the "dot" notation


---
## `svyttest` Example 1: One-sample t-test

- I keep my house at 68 degrees at night during the summer. Is this different from the national average?

```{r ttest_ex1}
recs_des %>%
   svyttest(design=.,
            formula=I(SummerTempNight-68)~0, #<<
            na.rm=TRUE)
```

???
- Note the I notation, this does the arithmetic before modeling


---
## `svyttest` Example 2: Comparing two variables

- Do people keep their house the same temperature at night during the summer and the winter?

```{r ttest_ex2}
recs_des %>%
   svyttest(design=.,
            formula=I(SummerTempNight-WinterTempNight)~0,
            na.rm=TRUE)
```

???
- this is a paired t-test
- testing whether the difference is 0 for each household


---
## `svyttest` Example 3: Two-sample t-test

- Are electric bills different between those with and without A/C?

```{r ttest_ex3}
recs_des %>%
   svyttest(design=.,
            formula=DOLLAREL~ACUsed,
            na.rm=TRUE)
```


---
## Linear Regression: `svyglm` Syntax

- As with t-tests, regressions are done in the package `survey` not `srvyr` but you can use the same design object

- Syntax is similar between t-test and glm

```{r glm_syn, eval=FALSE}
svyglm(formula, 
       design,
       na.action, #default is na.omit
       ....)
```


---
## `svyglm` Example 1: Dummy regression

Same example as two-sample t-test: Are electric bills different between those with and without A/C?

<b>t-test:</b>
```{r twosamp_ex_ttest, eval=FALSE}
recs_des %>%
   svyttest(design=.,
            formula=DOLLAREL~ACUsed,
            na.rm=TRUE) #<<
```

<b>glm:</b>
```{r twosamp_ex_glm, eval=FALSE}
recs_des %>%
   svyglm(design=.,
          formula=DOLLAREL~ACUsed,
          na.action=na.omit) #<<
```

???
- one major difference in how you specify to ignore NA values
- svyttest can only have 2-levels in group variable
- svyglm, the variable on right can be anything (continuous or factor)


---
## `svyglm` Example 1: Dummy regression

Are electric bills different between those with and without A/C?
.small[
```{r twosamp_ex_ttest_run}
recs_des %>%
   svyglm(design=.,
          formula=DOLLAREL~ACUsed,
          na.action=na.omit) %>%
  summary()
```
]

???
- same results as t-test


---
## `svyglm` Example 2: Multiple dummies

Does temperature of AC at night vary by region?
.smaller[
```{r anova_ex}
recs_des %>%
   svyglm(design=.,
          formula=SummerTempNight~Region,
          na.action=na.omit) %>%
  summary()

```
]

???
- Region is a factor variable, if it is numeric - this will treat it like a linear model


---
## `svyglm` Example 3: Continuous predictor

- Is there a relationship between square footage and electric bill?
- Let's review the data first with a ggplot. <i>Note we use the original data and do <b>NOT</b> use the survey design object.</i>

```{r plot_sf_elbill}
p <- recs %>%
  ggplot(aes(x=TOTSQFT_EN, y=DOLLAREL, weight=NWEIGHT)) +
  geom_hex(color="white") + 
  scale_fill_gradient(guide="colourbar",name="Count of Housing Units")

```

???
- When using the original data, make sure you include the weight variable

---
## `svyglm` Example 3: Continuous predictor
```{r plot_sf_elbill_disp, echo=FALSE, fig.asp=9/16, fig.align="center", out.width="90%", dpi=300}
p +
  theme_bw() 
```


---
## `svyglm` Example 3: Continuous predictor
.small[
```{r lm_ex}
m_electric_sqft <- recs_des %>%
   svyglm(design=.,
          formula=DOLLAREL~TOTSQFT_EN,
          na.action=na.omit)
summary(m_electric_sqft)
```
]

???
- for every additional square foot, the electricity cost is on average 24.6 cents more


---
## Practice time

- Open ContinuousExercises.Rmd and work through Part 2

- We will take 10 minutes. Use this time for the exercises and questions.



---
class: inverse center middle
# Categorical Dependent Variables


---
## Weighted Analysis for Categorical Variable

- Functions to use within `summarize` after `group_by`
  - survey_mean/survey_prop
  - survey_total

- Functions to get counts
  - survey_count

???

- we use the same mean and total functions as with continuous variables
- `survey_count` is new
- has a similar structure as the standard (non-survey) version of count


---
## `survey_count` Syntax

- `survey_count` functions similarly to `count` in that it is <b>NOT</b> called within `summarize`

- Produces weighted counts and variance of your choice of those counts
```{r survey_count_syn, eval=FALSE, tidy=FALSE}
survey_count(
   x,
   ...,
   wt = NULL,
   sort = FALSE,
   name = "n",
   .drop = dplyr::group_by_drop_default(x),
   vartype = c("se", "ci", "var", "cv")
)
```
???
- similar to count in that it takes one or many variables
- can change the variance type


---
## `survey_count` Example

- Cross-tab of population in each age group and gender
```{r survey_count_ex}
anes_des %>%
   survey_count(AgeGroup, Gender, name="N")

```

???

- `survey_count` is placed on its own like `count`
- it does NOT go in a `summarize` function
- can take multiple variables
- can change the output count name, `n` is the default


---
## `survey_mean` and `survey_total` within `summarize`

- Specify the sample design,
- then specify the crosstab in `group_by`,
- then `survey_mean` or `survey_prop` used with no x (variable) calculates a proportion of groups within `summarize`, or
- `survey_total` used with no x (variable) calculates a population count estimate within `summarize`


---
## `survey_mean` and `survey_prop` Syntax

```{r survey_mean_syn, eval=FALSE}
survey_mean(
   x,
   na.rm = FALSE,
   vartype = c("se", "ci", "var", "cv"),
   level = 0.95,
   proportion = FALSE,
   prop_method = c("logit", "likelihood", "asin", "beta", "mean"),
   deff = FALSE,
   df = NULL,
   ...
)

survey_prop(
  vartype = c("se", "ci", "var", "cv"),
  level = 0.95,
  proportion = FALSE,
  prop_method = c("logit", "likelihood", "asin", "beta", "mean"),
  deff = FALSE,
  df = NULL,
  ...
)
```

???

- `proportion`/ `prop_method` impact the CI only


---
## `survey_mean` and `survey_total` Examples

Looking at population by age group as done with `survey_count`.
```{r survey_p_ex1}
anes_des %>%
   group_by(AgeGroup) %>%
   summarize(
      p1=survey_mean(),
      p2=survey_prop(),
      N=survey_total(),
      n=unweighted(n()), # this gets unweighted counts aka sample sizes
      .groups="drop" # summarize option to remove groups
   )
```

???

- to get proportions we use `group_by` and `survey_mean`
- also use `survey_total` to get a population count estimate as before


---
## Conditional proportions with more than one group

- Specifying more than one group calculates conditional proportions
- Example: people voting in 2016 and 2020

```{r survey_p_cond, tidy=FALSE}
anes_des %>%
   filter(!is.na(VotedPres2016), !is.na(VotedPres2020)) %>%
   group_by(VotedPres2016, VotedPres2020) %>%
   summarize(
      p=survey_mean(),
      N=survey_total(),
      n=unweighted(n()), 
      .groups="drop"
   )
```

???

- We will talk more about this next time but filter after creating design object to subset data
- Note that this is the proportion of voting in 2020 by whether people voted in 2016
- What if we don't want conditional proportions?


---
## Joint proportions with more than one group

- Specify an interaction to get joint distribution - use `interact` within `group_by`
- Example: people voting in 2016 and 2020

```{r survey_p_joint}
anes_des %>%
   filter(!is.na(VotedPres2020), !is.na(VotedPres2016)) %>%
   group_by(interact(VotedPres2016, VotedPres2020)) %>% #<<
   summarize(
      p=survey_mean(),
      N=survey_total(),
      .groups="drop"
   )
```

???

- We add an interaction for the groups
- This outputs the joint distribution


---
## Proportions with Design Effects

```{r survey_p_deff}
anes_des %>%
   filter(!is.na(VotedPres2016), !is.na(VotedPres2020)) %>%
   group_by(interact(VotedPres2016, VotedPres2020)) %>% 
   summarize(
      p=survey_mean(deff=TRUE), #<<
      N=survey_total()
   )
```

???

- Use `deff=TRUE` option in the `survey_mean` function

 In survey research, the design effect is a number that shows how well a sample of people may represent a larger group of people for a specific measure of interest (such as the mean). This is important when the sample comes from a sampling method that is different than just picking people using a simple random sample.

The design effect is a positive real number, represented by the symbol Deff {\displaystyle {\text{Deff}}}. If Deff = 1 {\displaystyle {\text{Deff}}=1}, then the sample was selected in a way that is just as good as if people were picked randomly. When Deff > 1 {\displaystyle {\text{Deff}}>1}, then inference from the data collected is not as accurate as it could have been if people were picked randomly.

When researchers use complicated methods to pick their sample, they use the design effect to check and adjust their results. It may also be used when planning a study in order to determine the sample size. 


---
## Proportions: confidence intervals

```{r survey_p_ci, eval=FALSE}
anes_des %>%
   group_by(interact(Income7, VotedPres2016, VotedPres2020)) %>% 
   summarize(
      pd=survey_prop(vartype="ci") %>% round(4)
   ) %>% select(Income7, VotedPres2016, VotedPres2020, pd, contains("_")) %>%
   DT::datatable(fillContainer = FALSE, options = list(pageLength = 4))
```


---
## Proportions: confidence intervals (results)

```{r survey_p_ci_print, ref.label="survey_p_ci", eval=TRUE, echo=FALSE}
```

???

Note that some of the lower bounds are less than 0 for the default method

REMOVED PRACTICE PART 1 AND svychisq section HERE!


---
## Logistic regression with `svyglm`

```{r logisticsyntax, eval=FALSE}
svyglm(formula, # response ~ terms
       design,
       na.action, #default is na.omit
       family = quasibinomial, # use this to avoid warning about non-integers
       ....)
```


---
## Example logistic regression

- Predicting trust in government by who someone voted in 2020

```{r logisticexamp}
filter(anes_des, Weight>0) %>%
   svyglm(design=.,
          formula=TrustGovernment~ VotedPres2020_selection,
          family = quasibinomial) %>%
   summary()
```


---
## Practice time

- Open CategoricalExercises.Rmd and work through the questions

- We will take 15 minutes. Use this time for the exercises and questions.


---
class: inverse center middle

# Closing

---
## Resources for more learning

- Zimmer, Powell, and Velásquez. 2024. [Exploring Complex Survey Data Analysis Using R](https://tidy-survey-r.github.io/tidy-survey-book/).

- Online documentation for the [sampling package](https://cran.r-project.org/web/packages/sampling/index.html)

- https://cran.r-project.org/web/packages/srvyr/vignettes/srvyr-vs-survey.html

- https://r-survey.r-forge.r-project.org/survey/ (Includes more advanced modeling)

<br>

### Data Sources

- <font size="3">The American National Election Studies (https://electionstudies.org/). These materials are based on work supported by the National Science Foundation under grant numbers SES 1444721, 2014-2017, the University of Michigan, and Stanford University.  </font>

- <font size="3">*Residential Energy Consumption Survey: Using the 2015 Microdata File to Compute Estimates and Standard Errors.* U.S. Department of Energy (2017) https://www.eia.gov/consumption/residential/data/2015/pdf/microdata_v3.pdf </font>


